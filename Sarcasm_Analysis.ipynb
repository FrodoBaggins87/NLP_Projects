{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7UzestDpcUk5tovByMxr5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/NLP_Projects/blob/main/Sarcasm_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Libraries"
      ],
      "metadata": {
        "id": "pubLt11o1uii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "54diJz_jv2re"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data"
      ],
      "metadata": {
        "id": "4rB9aOCl11gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Initialize lists to store data\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "\n",
        "# Open the file and read it line by line\n",
        "with open('sarcasm.json', 'r') as f:\n",
        "    line_number = 1\n",
        "    for line in f:\n",
        "        try:\n",
        "            item = json.loads(line)\n",
        "            sentences.append(item['headline'])\n",
        "            labels.append(item['is_sarcastic'])\n",
        "            urls.append(item['article_link'])\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON on line {line_number}: {e}\")\n",
        "        line_number += 1\n",
        "\n",
        "# Now you have all the data in the lists\n",
        "print(f\"Total headlines: {len(sentences)}\")\n",
        "print(f\"First headline: {sentences[0]}\")\n",
        "print(f\"First label: {labels[0]}\")\n",
        "print(f\"First URL: {urls[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BVDZfa-15Xd",
        "outputId": "64bf4e52-e6dd-454d-a75f-59c457c12456"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error decoding JSON on line 14880: Unterminated string starting at: line 1 column 33 (char 32)\n",
            "Total headlines: 14879\n",
            "First headline: thirtysomething scientists unveil doomsday clock of hair loss\n",
            "First label: 1\n",
            "First URL: https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize"
      ],
      "metadata": {
        "id": "K1NRj6Fi_zZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer(oov_token=\"<OOV>\") #make tokenizer object\n",
        "tokenizer.fit_on_texts(sentences) #fitting only on training sentences not on testing sentences\n",
        "word_index=tokenizer.word_index\n",
        "sequences=tokenizer.texts_to_sequences(sentences)\n",
        "padded=pad_sequences(sequences,padding='post')\n",
        "print(padded[0])\n",
        "print(padded.shape)\n",
        "print(len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO23oLyQ_1n6",
        "outputId": "ed966e20-3442-4187-d04b-d9c5012d0ec3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10803   321  2710  5699  2711     3   513   911     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "(14879, 152)\n",
            "22326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Slice senteces and labels into training and test dataset"
      ],
      "metadata": {
        "id": "Ijb8-fZQ8egF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "percent=0.8\n",
        "training_size=int(len(sentences)*percent)\n",
        "training_sentences=sentences[0:training_size]\n",
        "training_labels=labels[0:training_size]\n",
        "testing_sentences=sentences[training_size:]\n",
        "testing_labels=labels[training_size:]"
      ],
      "metadata": {
        "id": "YEbViys18sO-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize training and testing separately"
      ],
      "metadata": {
        "id": "aIIH4Wsb7d6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=padded.shape[1]\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_token=\"<OOV>\"\n",
        "vocab_size=len(word_index) + 1"
      ],
      "metadata": {
        "id": "85lyfvRAAC94"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer(num_words=vocab_size, oov_token=oov_token) #make tokenizer object\n",
        "\n",
        "tokenizer.fit_on_texts(training_sentences) #fitting only on training sentences not on testing sentences\n",
        "\n",
        "word_index=tokenizer.word_index\n",
        "\n",
        "training_sequences=tokenizer.texts_to_sequences(training_sentences) #make sequences from tokens\n",
        "\n",
        "training_padded=pad_sequences(training_sequences,\n",
        "                              maxlen=max_length,\n",
        "                              padding=padding_type,\n",
        "                              truncating=trunc_type) #make padded sequences\n",
        "print(training_padded[0])\n",
        "print(training_padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rOWkZ2v7gEl",
        "outputId": "3c5b544b-d917-46ca-9128-11a4158ae31a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9414  297 2514 4811 2515    3  494  746    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "(11903, 152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sequences=tokenizer.texts_to_sequences(testing_sentences) #making sequences for testing dataset\n",
        "testing_padded=pad_sequences(testing_sequences,\n",
        "                             maxlen=max_length,\n",
        "                             padding=padding_type,\n",
        "                             truncating=trunc_type) #padding\n",
        "print(testing_padded[0])\n",
        "print(testing_padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bW5iIgT-WA6",
        "outputId": "75191e83-ada7-4683-fc05-35b4385f909d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   83    49    60    48 19799 19800    41  7025   592  9169     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "(2976, 152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Make the model"
      ],
      "metadata": {
        "id": "046bEtn9CBZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=100"
      ],
      "metadata": {
        "id": "7ObrZ_-3EEf9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WkNiN98ICCwf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Model"
      ],
      "metadata": {
        "id": "Rm_Wh9SfEeD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the types of your data\n",
        "print(type(training_padded))\n",
        "print(type(training_labels))\n",
        "print(type(testing_padded))\n",
        "print(type(testing_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGmn4-1vFbtL",
        "outputId": "21dda10c-1787-4231-de17-424a833cc0a7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numpy arrays if they are not already\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "iMN4RTPZFmD5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=35\n",
        "history=model.fit(training_padded,\n",
        "                  training_labels,\n",
        "                  epochs=num_epochs,\n",
        "                  validation_data=(testing_padded,testing_labels),\n",
        "                  verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d3eAgcAEgBP",
        "outputId": "86fee772-5753-4d93-f062-dbb327af48ea"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9120 - loss: 0.2216 - val_accuracy: 0.8454 - val_loss: 0.3612\n",
            "Epoch 2/35\n",
            "372/372 - 10s - 26ms/step - accuracy: 0.9144 - loss: 0.2147 - val_accuracy: 0.8485 - val_loss: 0.3564\n",
            "Epoch 3/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9264 - loss: 0.1916 - val_accuracy: 0.8411 - val_loss: 0.3838\n",
            "Epoch 4/35\n",
            "372/372 - 10s - 28ms/step - accuracy: 0.9366 - loss: 0.1654 - val_accuracy: 0.8448 - val_loss: 0.3724\n",
            "Epoch 5/35\n",
            "372/372 - 10s - 26ms/step - accuracy: 0.9388 - loss: 0.1605 - val_accuracy: 0.8468 - val_loss: 0.3748\n",
            "Epoch 6/35\n",
            "372/372 - 8s - 21ms/step - accuracy: 0.9449 - loss: 0.1461 - val_accuracy: 0.8471 - val_loss: 0.3830\n",
            "Epoch 7/35\n",
            "372/372 - 11s - 28ms/step - accuracy: 0.9477 - loss: 0.1342 - val_accuracy: 0.8239 - val_loss: 0.4338\n",
            "Epoch 8/35\n",
            "372/372 - 10s - 27ms/step - accuracy: 0.9569 - loss: 0.1167 - val_accuracy: 0.7732 - val_loss: 0.6310\n",
            "Epoch 9/35\n",
            "372/372 - 8s - 21ms/step - accuracy: 0.9560 - loss: 0.1185 - val_accuracy: 0.8038 - val_loss: 0.5330\n",
            "Epoch 10/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9573 - loss: 0.1149 - val_accuracy: 0.7631 - val_loss: 0.7140\n",
            "Epoch 11/35\n",
            "372/372 - 7s - 20ms/step - accuracy: 0.9639 - loss: 0.0970 - val_accuracy: 0.8495 - val_loss: 0.4097\n",
            "Epoch 12/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9752 - loss: 0.0728 - val_accuracy: 0.8031 - val_loss: 0.5800\n",
            "Epoch 13/35\n",
            "372/372 - 10s - 28ms/step - accuracy: 0.9680 - loss: 0.0882 - val_accuracy: 0.8411 - val_loss: 0.4484\n",
            "Epoch 14/35\n",
            "372/372 - 7s - 20ms/step - accuracy: 0.9638 - loss: 0.0962 - val_accuracy: 0.8444 - val_loss: 0.4380\n",
            "Epoch 15/35\n",
            "372/372 - 8s - 23ms/step - accuracy: 0.9707 - loss: 0.0810 - val_accuracy: 0.8441 - val_loss: 0.4485\n",
            "Epoch 16/35\n",
            "372/372 - 10s - 28ms/step - accuracy: 0.9821 - loss: 0.0535 - val_accuracy: 0.8202 - val_loss: 0.5443\n",
            "Epoch 17/35\n",
            "372/372 - 8s - 21ms/step - accuracy: 0.9805 - loss: 0.0562 - val_accuracy: 0.8347 - val_loss: 0.4964\n",
            "Epoch 18/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9822 - loss: 0.0528 - val_accuracy: 0.8390 - val_loss: 0.4955\n",
            "Epoch 19/35\n",
            "372/372 - 9s - 25ms/step - accuracy: 0.9866 - loss: 0.0419 - val_accuracy: 0.7520 - val_loss: 0.9286\n",
            "Epoch 20/35\n",
            "372/372 - 10s - 27ms/step - accuracy: 0.9803 - loss: 0.0561 - val_accuracy: 0.7829 - val_loss: 0.7925\n",
            "Epoch 21/35\n",
            "372/372 - 11s - 28ms/step - accuracy: 0.9677 - loss: 0.1014 - val_accuracy: 0.8404 - val_loss: 0.5043\n",
            "Epoch 22/35\n",
            "372/372 - 11s - 29ms/step - accuracy: 0.9902 - loss: 0.0331 - val_accuracy: 0.8350 - val_loss: 0.5449\n",
            "Epoch 23/35\n",
            "372/372 - 10s - 28ms/step - accuracy: 0.9870 - loss: 0.0391 - val_accuracy: 0.8172 - val_loss: 0.6284\n",
            "Epoch 24/35\n",
            "372/372 - 9s - 25ms/step - accuracy: 0.9841 - loss: 0.0481 - val_accuracy: 0.8236 - val_loss: 0.6150\n",
            "Epoch 25/35\n",
            "372/372 - 10s - 28ms/step - accuracy: 0.9804 - loss: 0.0519 - val_accuracy: 0.8038 - val_loss: 0.7325\n",
            "Epoch 26/35\n",
            "372/372 - 8s - 23ms/step - accuracy: 0.9914 - loss: 0.0273 - val_accuracy: 0.8327 - val_loss: 0.5719\n",
            "Epoch 27/35\n",
            "372/372 - 9s - 25ms/step - accuracy: 0.9930 - loss: 0.0239 - val_accuracy: 0.8189 - val_loss: 0.6710\n",
            "Epoch 28/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9760 - loss: 0.0638 - val_accuracy: 0.8310 - val_loss: 0.5861\n",
            "Epoch 29/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9949 - loss: 0.0183 - val_accuracy: 0.7933 - val_loss: 0.8344\n",
            "Epoch 30/35\n",
            "372/372 - 7s - 19ms/step - accuracy: 0.9954 - loss: 0.0176 - val_accuracy: 0.8296 - val_loss: 0.6249\n",
            "Epoch 31/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9719 - loss: 0.1061 - val_accuracy: 0.8132 - val_loss: 0.5625\n",
            "Epoch 32/35\n",
            "372/372 - 7s - 19ms/step - accuracy: 0.9753 - loss: 0.0754 - val_accuracy: 0.8054 - val_loss: 0.6287\n",
            "Epoch 33/35\n",
            "372/372 - 10s - 27ms/step - accuracy: 0.9943 - loss: 0.0278 - val_accuracy: 0.8202 - val_loss: 0.5688\n",
            "Epoch 34/35\n",
            "372/372 - 8s - 22ms/step - accuracy: 0.9939 - loss: 0.0255 - val_accuracy: 0.8330 - val_loss: 0.5216\n",
            "Epoch 35/35\n",
            "372/372 - 7s - 19ms/step - accuracy: 0.9761 - loss: 0.0634 - val_accuracy: 0.8175 - val_loss: 0.5883\n"
          ]
        }
      ]
    }
  ]
}